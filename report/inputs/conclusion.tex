Through exploratory analysis of 3.2\,M profile ratings we found a mildly right‑skewed 1--10 distribution, no significant outliers, and almost zero correlation between popularity and mean score. After memory‑efficient cleaning (74\,\% footprint reduction) and removal of 47 duplicate interactions we benchmarked three recommenders.

The simple item‑mean baseline already reached \textit{MAE}=1.46 on the held‑out set, outperforming a bias‑aware $k$‑NN collaborative filter. Adding lightweight content features (gender mix, popularity, residual bias) lowered the bias‑only baseline from 1.59 to 1.49 but still lagged behind the item‑mean.

These findings suggest that, given short user histories and limited metadata, identity‑level statistics explain most variance. Future work should explore latent‑factor or hybrid models enriched with temporal and demographic signals and evaluate ranking metrics better aligned with user experience.
